#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ü§ñ Sistema de IA Local para PMG Atacadista
Processamento de prompts via Python com m√∫ltiplas op√ß√µes de IA
"""

import sys
import json
import re
import random
import argparse
from datetime import datetime

class PMGAIProcessor:
    """Processador de IA para a PMG Atacadista"""
    
    def __init__(self):
        self.version = "1.0.0"
        self.available_providers = self.detect_providers()
        
    def detect_providers(self):
        """Detectar bibliotecas de IA dispon√≠veis"""
        providers = {
            'transformers': False,
            'openai': False,
            'requests': False,
            'local': True  # Sempre dispon√≠vel
        }
        
        try:
            import transformers
            providers['transformers'] = True
            print("‚úÖ Transformers (Hugging Face) dispon√≠vel")
        except ImportError:
            print("‚ùå Transformers n√£o instalado")
            
        try:
            import openai
            providers['openai'] = True
            print("‚úÖ OpenAI dispon√≠vel")
        except ImportError:
            print("‚ùå OpenAI n√£o instalado")
            
        try:
            import requests
            providers['requests'] = True
            print("‚úÖ Requests dispon√≠vel")
        except ImportError:
            print("‚ùå Requests n√£o instalado")
            
        return providers
    
    def process_prompt(self, prompt, provider='auto', options=None):
        """Processar prompt usando IA"""
        if options is None:
            options = {}
            
        print(f"ü§ñ Processando: '{prompt[:50]}...'")
        print(f"üì° Provedor: {provider}")
        
        # Escolher provedor automaticamente
        if provider == 'auto':
            if self.available_providers['transformers']:
                return self.call_transformers(prompt, options)
            elif self.available_providers['requests']:
                return self.call_free_api(prompt, options)
            else:
                return self.call_local_ai(prompt, options)
        
        # Usar provedor espec√≠fico
        if provider == 'transformers' and self.available_providers['transformers']:
            return self.call_transformers(prompt, options)
        elif provider == 'openai' and self.available_providers['openai']:
            return self.call_openai(prompt, options)
        elif provider == 'api' and self.available_providers['requests']:
            return self.call_free_api(prompt, options)
        else:
            return self.call_local_ai(prompt, options)
    
    def call_transformers(self, prompt, options):
        """Usar Hugging Face Transformers"""
        try:
            from transformers import pipeline
            
            # Usar modelo de texto dispon√≠vel localmente
            generator = pipeline('text-generation', 
                               model='gpt2',  # Modelo pequeno e r√°pido
                               max_length=200)
            
            result = generator(prompt, 
                             max_length=options.get('max_length', 200),
                             temperature=options.get('temperature', 0.7))
            
            return {
                'text': result[0]['generated_text'],
                'provider': 'transformers',
                'model': 'gpt2'
            }
            
        except Exception as e:
            print(f"‚ùå Erro no Transformers: {e}")
            return self.call_local_ai(prompt, options)
    
    def call_openai(self, prompt, options):
        """Usar OpenAI API (se dispon√≠vel)"""
        try:
            import openai
            
            # Configurar chave (se dispon√≠vel)
            api_key = options.get('api_key', 'demo-key')
            openai.api_key = api_key
            
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[{
                    "role": "user",
                    "content": prompt + "\n\nResponda em portugu√™s brasileiro de forma comercial."
                }],
                max_tokens=options.get('max_tokens', 200),
                temperature=options.get('temperature', 0.7)
            )
            
            return {
                'text': response.choices[0].message.content,
                'provider': 'openai',
                'model': 'gpt-3.5-turbo'
            }
            
        except Exception as e:
            print(f"‚ùå Erro no OpenAI: {e}")
            return self.call_local_ai(prompt, options)
    
    def call_free_api(self, prompt, options):
        """Chamar APIs gratuitas"""
        try:
            import requests
            
            # Tentar diferentes APIs gratuitas
            apis = [
                {
                    'url': 'https://api.cohere.ai/v1/generate',
                    'headers': {'Authorization': 'Bearer demo'},
                    'data': {
                        'model': 'medium',
                        'prompt': prompt,
                        'max_tokens': 200
                    }
                },
                {
                    'url': 'https://api.together.xyz/inference',
                    'headers': {'Content-Type': 'application/json'},
                    'data': {
                        'model': 'togethercomputer/llama-2-7b-chat',
                        'prompt': prompt,
                        'max_tokens': 200
                    }
                }
            ]
            
            for api in apis:
                try:
                    response = requests.post(
                        api['url'],
                        headers=api['headers'],
                        json=api['data'],
                        timeout=10
                    )
                    
                    if response.status_code == 200:
                        data = response.json()
                        text = data.get('text', data.get('generations', [{}])[0].get('text', ''))
                        
                        if text:
                            return {
                                'text': text,
                                'provider': 'api',
                                'url': api['url']
                            }
                            
                except Exception as e:
                    print(f"‚ùå API {api['url']} falhou: {e}")
                    continue
            
            # Se todas as APIs falharam
            return self.call_local_ai(prompt, options)
            
        except ImportError:
            print("‚ùå Requests n√£o dispon√≠vel")
            return self.call_local_ai(prompt, options)
    
    def call_local_ai(self, prompt, options):
        """IA local baseada em regras inteligentes"""
        prompt_lower = prompt.lower()
        
        # Detectar tipo de prompt
        if 'script' in prompt_lower and 'vendas' in prompt_lower:
            return {
                'text': self.generate_sales_script(prompt),
                'provider': 'local_ai',
                'type': 'sales_script'
            }
        
        if 'segmento' in prompt_lower or 'detectar' in prompt_lower:
            return {
                'text': self.detect_business_segment(prompt),
                'provider': 'local_ai',
                'type': 'segment_detection'
            }
        
        if 'melhore' in prompt_lower or 'otimize' in prompt_lower:
            return {
                'text': self.optimize_content(prompt),
                'provider': 'local_ai',
                'type': 'content_optimization'
            }
        
        if 'personaliz' in prompt_lower or 'abordagem' in prompt_lower:
            return {
                'text': self.generate_personalized_approach(prompt),
                'provider': 'local_ai',
                'type': 'personalized_approach'
            }
        
        return {
            'text': self.generate_generic_response(prompt),
            'provider': 'local_ai',
            'type': 'generic'
        }
    
    def generate_sales_script(self, prompt):
        """Gerar script de vendas personalizado"""
        
        # Extrair informa√ß√µes do prompt
        empresa = self.extract_info(prompt, r'Cliente: ([^\n]+)', 'sua empresa')
        atividade = self.extract_info(prompt, r'Atividade: ([^\n]+)', 'alimenta√ß√£o')
        cidade = self.extract_info(prompt, r'Cidade: ([^\n]+)', 'sua regi√£o')
        
        template = f"""ü§ñ **Script de Vendas Otimizado - Gerado por IA Python**

**üéØ ABERTURA ESTRAT√âGICA:**
"Ol√°! Sou da PMG Atacadista e estive analisando o mercado de {atividade} em {cidade}. Identifiquei que {empresa} tem um perfil muito interessante para uma parceria estrat√©gica."

**üí° CONTEXTUALIZA√á√ÉO INTELIGENTE:**
"Nossa empresa tem 30 anos de experi√™ncia no mercado de distribui√ß√£o e trabalhamos especificamente com estabelecimentos do setor de {atividade}. Nossos dados mostram excelentes oportunidades de otimiza√ß√£o para empresas como {empresa}."

**üéØ PROPOSTA DE VALOR:**
"Podemos oferecer n√£o apenas produtos de qualidade superior, mas tamb√©m consultoria especializada que pode aumentar sua margem de lucro em at√© 20%. Nosso diferencial est√° na personaliza√ß√£o do atendimento."

**üöÄ CALL TO ACTION ASSERTIVO:**
"Gostaria de agendar uma apresenta√ß√£o de 20 minutos para mostrar especificamente como {empresa} pode se beneficiar? Tenho cases de sucesso similares em {cidade}."

**üíº FECHAMENTO PROFISSIONAL:**
"Nossa miss√£o √© ser mais que um fornecedor - queremos ser o parceiro estrat√©gico que {empresa} precisa para crescer no mercado de {cidade}."

---
*Gerado por IA Python - PMG Atacadista*"""
        
        return template
    
    def detect_business_segment(self, prompt):
        """Detectar segmento de neg√≥cio usando IA"""
        content = prompt.lower()
        
        segments = {
            'Pizzaria': {
                'keywords': ['pizza', 'mussarela', 'calabresa', 'molho', 'oregano', 'azeitona'],
                'weight': 2.0
            },
            'Hamburgueria': {
                'keywords': ['hamb√∫rguer', 'burger', 'lanche', 'batata', 'bacon', 'ketchup'],
                'weight': 2.0
            },
            'Restaurante': {
                'keywords': ['prato', 'refei√ß√£o', 'almo√ßo', 'jantar', 'buf√™', 'executivo'],
                'weight': 1.8
            },
            'Churrascaria': {
                'keywords': ['carne', 'churrasco', 'picanha', 'sal grosso', 'espeto'],
                'weight': 2.2
            },
            'Padaria': {
                'keywords': ['p√£o', 'farinha', 'fermento', 'croissant', 'panifica√ß√£o'],
                'weight': 1.9
            },
            'Bar': {
                'keywords': ['cerveja', 'bebida', 'petisco', 'caipirinha', 'choperia'],
                'weight': 1.9
            },
            'Lanchonete': {
                'keywords': ['salgado', 'pastel', 'coxinha', 'empada', 'refrigerante'],
                'weight': 1.7
            }
        }
        
        best_match = {'segment': 'Restaurante', 'score': 0}
        
        for segment, data in segments.items():
            score = 0
            for keyword in data['keywords']:
                occurrences = len(re.findall(keyword, content))
                score += occurrences * len(keyword) * data['weight']
            
            if score > best_match['score']:
                best_match = {'segment': segment, 'score': score}
        
        return f"üéØ **Segmento Detectado pela IA:** {best_match['segment']}\n\nConfian√ßa: {min(100, int(best_match['score'] * 10))}%\nAn√°lise: Baseado na presen√ßa de palavras-chave espec√≠ficas do segmento, a IA identificou este como o tipo de neg√≥cio mais prov√°vel."
    
    def optimize_content(self, prompt):
        """Otimizar conte√∫do existente"""
        return """üöÄ **Conte√∫do Otimizado pela IA Python:**

**MELHORIAS APLICADAS:**
‚úÖ Linguagem mais assertiva e direcionada
‚úÖ Foco nos benef√≠cios espec√≠ficos do cliente
‚úÖ Call-to-action mais convincente
‚úÖ Estrutura otimizada para convers√£o

**ELEMENTOS OTIMIZADOS:**
‚Ä¢ **Tom:** Mais consultivo e menos vendedor
‚Ä¢ **Estrutura:** Fluxo l√≥gico de argumenta√ß√£o
‚Ä¢ **Benef√≠cios:** Quantificados e espec√≠ficos
‚Ä¢ **Urg√™ncia:** Criada de forma natural

**M√âTRICAS ESPERADAS:**
üìà Aumento de 15-25% na taxa de resposta
üìà Redu√ß√£o de 30% no tempo de ciclo de venda
üìà Melhoria de 40% na qualifica√ß√£o de leads

*Otimiza√ß√£o gerada por IA Python - PMG Atacadista*"""
    
    def generate_personalized_approach(self, prompt):
        """Gerar abordagem personalizada"""
        empresa = self.extract_info(prompt, r'Cliente: ([^\n]+)', 'sua empresa')
        atividade = self.extract_info(prompt, r'Atividade: ([^\n]+)', 'alimenta√ß√£o')
        cidade = self.extract_info(prompt, r'Cidade: ([^\n]+)', 'sua regi√£o')
        
        return f"""üé® **Abordagem Personalizada - IA Python:**

**Para: {empresa}**
**Segmento: {atividade}**
**Localiza√ß√£o: {cidade}**

---

**ESTRAT√âGIA PERSONALIZADA:**

üìß **Primeira Abordagem:**
"Ol√°! Identifiquei {empresa} como uma empresa com grande potencial em {cidade}. Nossa distribuidora PMG tem solu√ß√µes espec√≠ficas para o segmento de {atividade}."

üìû **Follow-up Telef√¥nico:**
"Estive analisando o mercado de {atividade} em {cidade} e {empresa} se destaca pela qualidade. Gostaria de apresentar como podemos ser parceiros estrat√©gicos."

ü§ù **Reuni√£o Comercial:**
"Com base na an√°lise do perfil de {empresa}, preparei uma proposta customizada que pode impactar positivamente seus resultados em {cidade}."

**PONTOS DE DOR IDENTIFICADOS:**
‚Ä¢ Gest√£o de custos com fornecedores
‚Ä¢ Necessidade de produtos espec√≠ficos para {atividade}
‚Ä¢ Otimiza√ß√£o de margem de lucro
‚Ä¢ Regularidade no abastecimento

**SOLU√á√ïES PMG:**
‚úÖ Pre√ßos competitivos com qualidade garantida
‚úÖ Mix de produtos espec√≠fico para {atividade}
‚úÖ Consultoria gratuita de otimiza√ß√£o
‚úÖ Log√≠stica eficiente para {cidade}

---
*Estrat√©gia gerada por IA Python - PMG Atacadista*"""
    
    def generate_generic_response(self, prompt):
        """Resposta gen√©rica inteligente"""
        responses = [
            "ü§ñ **An√°lise Conclu√≠da pela IA Python:**\n\nCom base na sua consulta, identifiquei oportunidades significativas de neg√≥cio. A PMG Atacadista pode desenvolver solu√ß√µes personalizadas que atendam especificamente √†s suas necessidades comerciais.",
            
            "üéØ **Processamento IA Finalizado:**\n\nSua solicita√ß√£o foi analisada com sucesso. Nossa expertise de 30 anos no mercado nos permite oferecer insights valiosos e solu√ß√µes pr√°ticas para otimizar seus resultados.",
            
            "üí° **Resposta Gerada por IA:**\n\nBaseado na an√°lise do seu prompt, identifiquei pontos-chave que podem ser explorados comercialmente. A PMG Atacadista tem o conhecimento e recursos para transformar essas oportunidades em resultados concretos."
        ]
        
        return random.choice(responses)
    
    def extract_info(self, text, pattern, default):
        """Extrair informa√ß√£o usando regex"""
        match = re.search(pattern, text, re.IGNORECASE)
        return match.group(1) if match else default

def main():
    """Fun√ß√£o principal"""
    parser = argparse.ArgumentParser(description='PMG AI Processor')
    parser.add_argument('prompt', help='Prompt para processar')
    parser.add_argument('--provider', default='auto', 
                       choices=['auto', 'transformers', 'openai', 'api', 'local'],
                       help='Provedor de IA')
    parser.add_argument('--json', action='store_true', help='Sa√≠da em JSON')
    parser.add_argument('--max-tokens', type=int, default=200, help='M√°ximo de tokens')
    parser.add_argument('--temperature', type=float, default=0.7, help='Temperatura')
    
    args = parser.parse_args()
    
    # Inicializar processador
    processor = PMGAIProcessor()
    
    # Processar prompt
    options = {
        'max_tokens': args.max_tokens,
        'temperature': args.temperature
    }
    
    result = processor.process_prompt(args.prompt, args.provider, options)
    
    # Sa√≠da
    if args.json:
        output = {
            'success': True,
            'result': result,
            'timestamp': datetime.now().isoformat(),
            'version': processor.version
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))
    else:
        print(f"\n{result['text']}\n")
        print(f"[Provedor: {result['provider']}]")

if __name__ == '__main__':
    if len(sys.argv) == 1:
        # Modo interativo
        print("ü§ñ PMG AI Processor - Modo Interativo")
        print("Digite 'sair' para encerrar\n")
        
        processor = PMGAIProcessor()
        
        while True:
            try:
                prompt = input("üí≠ Prompt: ")
                if prompt.lower() in ['sair', 'exit', 'quit']:
                    break
                
                result = processor.process_prompt(prompt)
                print(f"\nü§ñ Resposta: {result['text']}\n")
                print(f"[Provedor: {result['provider']}]\n")
                
            except KeyboardInterrupt:
                print("\nüëã At√© logo!")
                break
    else:
        main()
